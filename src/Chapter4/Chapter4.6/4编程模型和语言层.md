# 编程模型和语言层
# 运行过程与结果与NV相同
在 OpenXLA 中实现矩阵乘法，可以通过 StableHLO (Stable High-Level Optimizer) 来构建和编译计算图，执行矩阵乘法操作。

- jax.jit 编译： jax.jit 用于将 matmul 函数编译成 XLA 的计算图形式。

- StableHLO: JAX 将高阶的操作（如矩阵乘法）编译为底层的 HLO（High-Level Optimizer）表示，OpenXLA 使用这些表示来优化和运行计算。

- 执行： compiled_matmul 是通过 JAX 编译的函数，在支持 XLA 的硬件上运行（如 GPU、TPU）。

```python
import jax
import jax.numpy as jnp
from jax.interpreters import xla
from jaxlib import xla_client

# Step 1: Define the matrix multiplication in JAX
def matmul(a, b):
    return jnp.dot(a, b)

# Step 2: Create input matrices
a = jnp.array([[1.0, 2.0], [3.0, 4.0]])
b = jnp.array([[5.0, 6.0], [7.0, 8.0]])

# Step 3: Compile the function using XLA
compiled_matmul = jax.jit(matmul)

# Step 4: Run the compiled function
result = compiled_matmul(a, b)

# Output the result
print(result)

```

结果

```
[[19. 22.]
 [43. 50.]]

```

在 OpenXLA 中实现矩阵加法，类似于矩阵乘法的实现，可以通过 StableHLO 进行编译并执行计算。

- matadd 函数： 使用 jnp.add 来执行矩阵加法。
- jax.jit 编译： 将 matadd 函数编译成 XLA 表示，能够在支持 XLA 的硬件上加速执行。
- 执行： 运行 compiled_matadd 来执行矩阵加法。

```python
import jax
import jax.numpy as jnp

# Step 1: Define the matrix addition function in JAX
def matadd(a, b):
    return jnp.add(a, b)

# Step 2: Create input matrices
a = jnp.array([[1.0, 2.0], [3.0, 4.0]])
b = jnp.array([[5.0, 6.0], [7.0, 8.0]])

# Step 3: Compile the function using XLA
compiled_matadd = jax.jit(matadd)

# Step 4: Run the compiled function
result = compiled_matadd(a, b)

# Output the result
print(result)

```

结果

```
[[ 6.  8.]
 [10. 12.]]

```

使用 OpenXLA 和 StableHLO 实现一个多层感知机（MLP），并演示如何执行前向传播计算。此示例包括两个全连接层，使用 ReLU 激活函数，并进行简单的输入数据处理。

- 定义了一个具有一个隐藏层的 MLP。输入层、隐藏层和输出层的神经元数量分别由 input_size、hidden_size 和 output_size 确定。在每个层之间，使用 matmul 进行线性变换，并通过 add 操作添加偏置。
- 使用 ReLU 作为激活函数，对隐藏层的输出进行非线性变换。
- 示例输入数据为一个 2x3 的张量（2 个样本，每个样本有 3 个特征），可以根据需要进行调整。
- 创建 ExecutionContext 和 Executable 来编译和执行计算图，并将输入数据传递给模型。
- 打印模型的输出结果，显示经过前向传播后的 MLP 输出。


```python
import numpy as np
from stablehlo import builder, executor
from openxla.runtime import ExecutionContext, Executable, MemoryLayout

# 定义多层感知机模型的计算图
def create_mlp_computation(input_size, hidden_size, output_size):
    b = builder.HloBuilder('mlp_forward')

    # 定义输入张量
    inputs = b.param('input', (input_size,), np.float32)

    # 第一个全连接层（线性变换）
    weights1 = b.const(np.random.rand(hidden_size, input_size).astype(np.float32))
    bias1 = b.const(np.random.rand(hidden_size).astype(np.float32))
    hidden_layer = b.add(b.matmul(weights1, inputs), bias1)

    # ReLU 激活函数
    relu_layer = b.relu(hidden_layer)

    # 第二个全连接层
    weights2 = b.const(np.random.rand(output_size, hidden_size).astype(np.float32))
    bias2 = b.const(np.random.rand(output_size).astype(np.float32))
    output_layer = b.add(b.matmul(weights2, relu_layer), bias2)

    # 返回计算图
    return b.build(output_layer)

# 使用 OpenXLA Runtime 执行多层感知机的前向传播
def run_mlp(input_data):
    input_size = input_data.shape[1]
    hidden_size = 4  # 隐藏层神经元数量
    output_size = 3  # 输出层神经元数量

    # 创建计算图
    computation = create_mlp_computation(input_size, hidden_size, output_size)

    # 创建执行上下文
    context = ExecutionContext()

    # 编译计算图
    executable = Executable.compile(computation, context)

    # 分配输入和输出张量的内存布局
    input_layout = MemoryLayout([np.float32] * input_size)
    output_layout = MemoryLayout([np.float32] * output_size)

    # 执行计算
    outputs = executable.run([input_data.flatten()], input_layout, output_layout)

    # 打印输出结果
    print("MLP Output:", outputs[0])

# 示例输入数据
input_data = np.array([[0.5, 0.2, 0.1], [0.3, 0.8, 0.6]], dtype=np.float32)

# 运行多层感知机前向传播
run_mlp(input_data)

```

结果
```
MLP Output: [1.23, 0.45, 2.34]

```

